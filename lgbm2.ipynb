{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "from data_loader import data_loader # 자체적으로 만든 data loader ([데이콘 15회 대회] 데이터 설명 및 데이터 불러오기 영상 참조)\n",
    "from tqdm import tqdm\n",
    "import joblib # 모델을 저장하고 불러오는 역할\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_all(func, path, train, nrows, **kwargs):\n",
    "    '''\n",
    "    Parameters:\n",
    "    \n",
    "    func: 하나의 csv파일을 읽는 함수 \n",
    "    path: [str] train용 또는 test용 csv 파일들이 저장되어 있는 폴더 \n",
    "    train: [boolean] train용 파일들 불러올 시 True, 아니면 False\n",
    "    nrows: [int] csv 파일에서 불러올 상위 n개의 row \n",
    "    lookup_table: [pd.DataFrame] train_label.csv 파일을 저장한 변수 \n",
    "    event_time: [int] 상태_B 발생 시간 \n",
    "    normal: [int] 상태_A의 라벨\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    combined_df: 병합된 train 또는 test data\n",
    "    '''\n",
    "    \n",
    "    # 읽어올 파일들만 경로 저장 해놓기 \n",
    "    files_in_dir = os.listdir(path)\n",
    "    \n",
    "    files_path = [path+'/'+file for file in files_in_dir]\n",
    "    \n",
    "    if train :\n",
    "        func_fixed = partial(func, nrows = nrows, train = True, lookup_table = kwargs['lookup_table'], event_time = kwargs['event_time'], normal = kwargs['normal'])\n",
    "        \n",
    "    else : \n",
    "        func_fixed = partial(func, nrows = nrows, train = False)\n",
    "    \n",
    "    \n",
    "    # 여러개의 코어를 활용하여 데이터 읽기 \n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool(processes = multiprocessing.cpu_count()) \n",
    "        df_list = list(tqdm(pool.imap(func_fixed, files_path), total = len(files_path)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "    # 데이터 병합하기 \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "test_path  = 'test'\n",
    "label = pd.read_csv('train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 828/828 [01:24<00:00,  9.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 720/720 [00:57<00:00, 12.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train = data_loader_all(data_loader, path = train_path, train = True, nrows = 150, normal = 999, event_time = 10, lookup_table = label)\n",
    "test  = data_loader_all(data_loader, path = test_path, train = False, nrows = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrain = train[train['label']!=999]\n",
    "X = newTrain.drop(['label', 'time', 'id'], axis=1)\n",
    "y = newTrain['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTest = test[test['time']>=10]\n",
    "newTest = newTest.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgbm.Dataset(X_train, y_train, free_raw_data=False)\n",
    "d_valid = lgbm.Dataset(X_valid, y_valid, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'task': 'train',\n",
    "    'boosting_type': 'goss',\n",
    "    #'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':198,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.002233,\n",
    "    'max_depth': 9,\n",
    "    #'num_leaves': 75,\n",
    "    'feature_fraction': 0.7,\n",
    "    'scale_pos_weight': 1.2,\n",
    "    #'bagging_fraction': 0.4,\n",
    "    #'bagging_freq': 10,\n",
    "    #'bagging_seed': 7,\n",
    "    'seed': 7,\n",
    "    'save_binary': True}\n",
    "    #'device':'gpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's multi_logloss: 2.89327\n",
      "[100]\tvalid_0's multi_logloss: 2.31576\n",
      "[150]\tvalid_0's multi_logloss: 1.959\n",
      "[200]\tvalid_0's multi_logloss: 1.70164\n",
      "[250]\tvalid_0's multi_logloss: 1.50211\n",
      "[300]\tvalid_0's multi_logloss: 1.34026\n",
      "[350]\tvalid_0's multi_logloss: 1.20539\n",
      "[400]\tvalid_0's multi_logloss: 1.09089\n",
      "[450]\tvalid_0's multi_logloss: 0.992453\n",
      "[500]\tvalid_0's multi_logloss: 0.908807\n",
      "[550]\tvalid_0's multi_logloss: 0.834904\n",
      "[600]\tvalid_0's multi_logloss: 0.769373\n",
      "[650]\tvalid_0's multi_logloss: 0.710883\n",
      "[700]\tvalid_0's multi_logloss: 0.65864\n",
      "[750]\tvalid_0's multi_logloss: 0.61201\n",
      "[800]\tvalid_0's multi_logloss: 0.570275\n",
      "[850]\tvalid_0's multi_logloss: 0.532816\n",
      "[900]\tvalid_0's multi_logloss: 0.499189\n",
      "[950]\tvalid_0's multi_logloss: 0.468978\n",
      "[1000]\tvalid_0's multi_logloss: 0.441813\n",
      "[1050]\tvalid_0's multi_logloss: 0.417309\n",
      "[1100]\tvalid_0's multi_logloss: 0.395198\n",
      "[1150]\tvalid_0's multi_logloss: 0.375244\n",
      "[1200]\tvalid_0's multi_logloss: 0.357162\n",
      "[1250]\tvalid_0's multi_logloss: 0.340825\n",
      "[1300]\tvalid_0's multi_logloss: 0.326039\n",
      "[1350]\tvalid_0's multi_logloss: 0.312621\n",
      "[1400]\tvalid_0's multi_logloss: 0.300442\n",
      "[1450]\tvalid_0's multi_logloss: 0.289401\n",
      "[1500]\tvalid_0's multi_logloss: 0.279378\n",
      "[1550]\tvalid_0's multi_logloss: 0.270251\n",
      "[1600]\tvalid_0's multi_logloss: 0.261953\n",
      "[1650]\tvalid_0's multi_logloss: 0.254413\n",
      "[1700]\tvalid_0's multi_logloss: 0.247529\n",
      "[1750]\tvalid_0's multi_logloss: 0.241299\n",
      "[1800]\tvalid_0's multi_logloss: 0.23555\n",
      "[1850]\tvalid_0's multi_logloss: 0.230275\n",
      "[1900]\tvalid_0's multi_logloss: 0.225475\n",
      "[1950]\tvalid_0's multi_logloss: 0.221082\n",
      "[2000]\tvalid_0's multi_logloss: 0.217049\n",
      "[2050]\tvalid_0's multi_logloss: 0.21334\n",
      "[2100]\tvalid_0's multi_logloss: 0.209961\n",
      "[2150]\tvalid_0's multi_logloss: 0.206809\n",
      "[2200]\tvalid_0's multi_logloss: 0.203946\n",
      "[2250]\tvalid_0's multi_logloss: 0.201311\n",
      "[2300]\tvalid_0's multi_logloss: 0.198873\n",
      "[2350]\tvalid_0's multi_logloss: 0.19664\n",
      "[2400]\tvalid_0's multi_logloss: 0.194582\n",
      "[2450]\tvalid_0's multi_logloss: 0.192658\n",
      "[2500]\tvalid_0's multi_logloss: 0.190897\n",
      "[2550]\tvalid_0's multi_logloss: 0.18926\n",
      "[2600]\tvalid_0's multi_logloss: 0.187711\n",
      "[2650]\tvalid_0's multi_logloss: 0.186252\n",
      "[2700]\tvalid_0's multi_logloss: 0.184919\n",
      "[2750]\tvalid_0's multi_logloss: 0.183646\n",
      "[2800]\tvalid_0's multi_logloss: 0.182457\n",
      "[2850]\tvalid_0's multi_logloss: 0.181352\n",
      "[2900]\tvalid_0's multi_logloss: 0.180315\n",
      "[2950]\tvalid_0's multi_logloss: 0.179347\n",
      "[3000]\tvalid_0's multi_logloss: 0.178435\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's multi_logloss: 0.178435\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgbm.train(params, d_train, 3000, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=100, evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgb_clf.predict(newTest.drop(['id'], axis=1))\n",
    "\n",
    "result = pd.DataFrame(data=pred)\n",
    "result.index = newTest.id\n",
    "result.index.name = 'id'\n",
    "result = result.sort_index()\n",
    "result = result.groupby('id').mean()\n",
    "\n",
    "\"\"\"scaler = MinMaxScaler(feature_range=(0.00001, 0.99999))\n",
    "tmp    = []\n",
    "\n",
    "for row in result.iterrows():\n",
    "    scaler.fit(row[1].to_frame())\n",
    "    tmp.append([r[0] for r in scaler.transform(row[1].to_frame())])\n",
    "    \n",
    "submission = pd.DataFrame(tmp, columns = result.columns)\n",
    "submission.index = result.index\n",
    "\"\"\"\n",
    "result.to_csv('submission_last2.csv', index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame(data = lgb_clf.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv('lgb3000_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=198)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4dfaecfc1df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\guswns\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m    537\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 538\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\guswns\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 89\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=198)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "r2_score(y_valid, lgb_clf.predict(X_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
